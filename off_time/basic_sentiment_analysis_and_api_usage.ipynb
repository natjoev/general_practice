{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "364d6619",
   "metadata": {},
   "source": [
    "# **Data Science Practice Project 2: Sentiment Analysis**\n",
    "#### credits to Siraj Raval - YT\n",
    "\n",
    "### some terms:\n",
    "- API or Application Programming Interface: a gateway that lets you acces a server's internal functionality (acc. to Siraj)\n",
    "- Tokenization: the process of assigning/representing values to words or phrases based on a criteria\n",
    "- Lexicon-Based: after tokenization, they are now placed on a set (called \"bag of words\"). These tokens are then analyzed based on an algorithm. Tokens are then assigned a sentiment value based on the algorithm. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a478317",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tweepy in c:\\users\\ael\\onedrive\\desktop\\138\\.venv\\lib\\site-packages (4.16.0)\n",
      "Requirement already satisfied: oauthlib<4,>=3.2.0 in c:\\users\\ael\\onedrive\\desktop\\138\\.venv\\lib\\site-packages (from tweepy) (3.3.1)\n",
      "Requirement already satisfied: requests<3,>=2.27.0 in c:\\users\\ael\\onedrive\\desktop\\138\\.venv\\lib\\site-packages (from tweepy) (2.32.5)\n",
      "Requirement already satisfied: requests-oauthlib<3,>=1.2.0 in c:\\users\\ael\\onedrive\\desktop\\138\\.venv\\lib\\site-packages (from tweepy) (2.0.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\ael\\onedrive\\desktop\\138\\.venv\\lib\\site-packages (from requests<3,>=2.27.0->tweepy) (3.4.3)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\ael\\onedrive\\desktop\\138\\.venv\\lib\\site-packages (from requests<3,>=2.27.0->tweepy) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\ael\\onedrive\\desktop\\138\\.venv\\lib\\site-packages (from requests<3,>=2.27.0->tweepy) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\ael\\onedrive\\desktop\\138\\.venv\\lib\\site-packages (from requests<3,>=2.27.0->tweepy) (2025.8.3)\n",
      "^C\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting textblob\n",
      "  Downloading textblob-0.19.0-py3-none-any.whl.metadata (4.4 kB)\n",
      "Collecting nltk>=3.9 (from textblob)\n",
      "  Downloading nltk-3.9.1-py3-none-any.whl.metadata (2.9 kB)\n",
      "Collecting click (from nltk>=3.9->textblob)\n",
      "  Downloading click-8.3.0-py3-none-any.whl.metadata (2.6 kB)\n",
      "Requirement already satisfied: joblib in c:\\users\\ael\\onedrive\\desktop\\138\\.venv\\lib\\site-packages (from nltk>=3.9->textblob) (1.5.2)\n",
      "Collecting regex>=2021.8.3 (from nltk>=3.9->textblob)\n",
      "  Downloading regex-2025.9.18-cp313-cp313-win_amd64.whl.metadata (41 kB)\n",
      "Collecting tqdm (from nltk>=3.9->textblob)\n",
      "  Downloading tqdm-4.67.1-py3-none-any.whl.metadata (57 kB)\n",
      "Requirement already satisfied: colorama in c:\\users\\ael\\onedrive\\desktop\\138\\.venv\\lib\\site-packages (from click->nltk>=3.9->textblob) (0.4.6)\n",
      "Downloading textblob-0.19.0-py3-none-any.whl (624 kB)\n",
      "   ---------------------------------------- 0.0/624.3 kB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/624.3 kB ? eta -:--:--\n",
      "   ---------------- ----------------------- 262.1/624.3 kB ? eta -:--:--\n",
      "   ---------------- ----------------------- 262.1/624.3 kB ? eta -:--:--\n",
      "   ---------------- ----------------------- 262.1/624.3 kB ? eta -:--:--\n",
      "   ---------------- ----------------------- 262.1/624.3 kB ? eta -:--:--\n",
      "   ---------------- ----------------------- 262.1/624.3 kB ? eta -:--:--\n",
      "   ---------------- ----------------------- 262.1/624.3 kB ? eta -:--:--\n",
      "   ---------------- ----------------------- 262.1/624.3 kB ? eta -:--:--\n",
      "   ---------------- ----------------------- 262.1/624.3 kB ? eta -:--:--\n",
      "   ------------------------------- ------ 524.3/624.3 kB 171.3 kB/s eta 0:00:01\n",
      "   ------------------------------- ------ 524.3/624.3 kB 171.3 kB/s eta 0:00:01\n",
      "   ------------------------------- ------ 524.3/624.3 kB 171.3 kB/s eta 0:00:01\n",
      "   ---------------------------------------- 624.3/624.3 kB 166.0 kB/s  0:00:02\n",
      "Downloading nltk-3.9.1-py3-none-any.whl (1.5 MB)\n",
      "   ---------------------------------------- 0.0/1.5 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/1.5 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/1.5 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/1.5 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/1.5 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/1.5 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/1.5 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/1.5 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/1.5 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/1.5 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/1.5 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/1.5 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/1.5 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/1.5 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/1.5 MB ? eta -:--:--\n",
      "   ------ --------------------------------- 0.3/1.5 MB ? eta -:--:--\n",
      "   ------ --------------------------------- 0.3/1.5 MB ? eta -:--:--\n",
      "   ------ --------------------------------- 0.3/1.5 MB ? eta -:--:--\n",
      "   ------ --------------------------------- 0.3/1.5 MB ? eta -:--:--\n",
      "   ------ --------------------------------- 0.3/1.5 MB ? eta -:--:--\n",
      "   ------ --------------------------------- 0.3/1.5 MB ? eta -:--:--\n",
      "   ------ --------------------------------- 0.3/1.5 MB ? eta -:--:--\n",
      "   ------ --------------------------------- 0.3/1.5 MB ? eta -:--:--\n",
      "   ------ --------------------------------- 0.3/1.5 MB ? eta -:--:--\n",
      "   ------ --------------------------------- 0.3/1.5 MB ? eta -:--:--\n",
      "   ------ --------------------------------- 0.3/1.5 MB ? eta -:--:--\n",
      "   ------ --------------------------------- 0.3/1.5 MB ? eta -:--:--\n",
      "   ------ --------------------------------- 0.3/1.5 MB ? eta -:--:--\n",
      "   ------ --------------------------------- 0.3/1.5 MB ? eta -:--:--\n",
      "   ------ --------------------------------- 0.3/1.5 MB ? eta -:--:--\n",
      "   ------ --------------------------------- 0.3/1.5 MB ? eta -:--:--\n",
      "   ------------- -------------------------- 0.5/1.5 MB 76.7 kB/s eta 0:00:13\n",
      "   ------------- -------------------------- 0.5/1.5 MB 76.7 kB/s eta 0:00:13\n",
      "   ------------- -------------------------- 0.5/1.5 MB 76.7 kB/s eta 0:00:13\n",
      "   ------------- -------------------------- 0.5/1.5 MB 76.7 kB/s eta 0:00:13\n",
      "   ------------- -------------------------- 0.5/1.5 MB 76.7 kB/s eta 0:00:13\n",
      "   ------------- -------------------------- 0.5/1.5 MB 76.7 kB/s eta 0:00:13\n",
      "   ------------- -------------------------- 0.5/1.5 MB 76.7 kB/s eta 0:00:13\n",
      "   ------------- -------------------------- 0.5/1.5 MB 76.7 kB/s eta 0:00:13\n",
      "   ------------- -------------------------- 0.5/1.5 MB 76.7 kB/s eta 0:00:13\n",
      "   ------------- -------------------------- 0.5/1.5 MB 76.7 kB/s eta 0:00:13\n",
      "   -------------------- ------------------- 0.8/1.5 MB 96.7 kB/s eta 0:00:08\n",
      "   -------------------- ------------------- 0.8/1.5 MB 96.7 kB/s eta 0:00:08\n",
      "   -------------------- ------------------- 0.8/1.5 MB 96.7 kB/s eta 0:00:08\n",
      "   -------------------- ------------------- 0.8/1.5 MB 96.7 kB/s eta 0:00:08\n",
      "   -------------------- ------------------- 0.8/1.5 MB 96.7 kB/s eta 0:00:08\n",
      "   -------------------- ------------------- 0.8/1.5 MB 96.7 kB/s eta 0:00:08\n",
      "   -------------------- ------------------- 0.8/1.5 MB 96.7 kB/s eta 0:00:08\n",
      "   -------------------- ------------------- 0.8/1.5 MB 96.7 kB/s eta 0:00:08\n",
      "   -------------------- ------------------- 0.8/1.5 MB 96.7 kB/s eta 0:00:08\n",
      "   -------------------- ------------------- 0.8/1.5 MB 96.7 kB/s eta 0:00:08\n",
      "   -------------------- ------------------- 0.8/1.5 MB 96.7 kB/s eta 0:00:08\n",
      "   -------------------- ------------------- 0.8/1.5 MB 96.7 kB/s eta 0:00:08\n",
      "   -------------------- ------------------- 0.8/1.5 MB 96.7 kB/s eta 0:00:08\n",
      "   -------------------- ------------------- 0.8/1.5 MB 96.7 kB/s eta 0:00:08\n",
      "   --------------------------- ------------ 1.0/1.5 MB 95.4 kB/s eta 0:00:05\n",
      "   --------------------------- ------------ 1.0/1.5 MB 95.4 kB/s eta 0:00:05\n",
      "   --------------------------- ------------ 1.0/1.5 MB 95.4 kB/s eta 0:00:05\n",
      "   --------------------------- ------------ 1.0/1.5 MB 95.4 kB/s eta 0:00:05\n",
      "   --------------------------- ------------ 1.0/1.5 MB 95.4 kB/s eta 0:00:05\n",
      "   --------------------------- ------------ 1.0/1.5 MB 95.4 kB/s eta 0:00:05\n",
      "   --------------------------- ------------ 1.0/1.5 MB 95.4 kB/s eta 0:00:05\n",
      "   --------------------------- ------------ 1.0/1.5 MB 95.4 kB/s eta 0:00:05\n",
      "   --------------------------- ------------ 1.0/1.5 MB 95.4 kB/s eta 0:00:05\n",
      "   --------------------------- ------------ 1.0/1.5 MB 95.4 kB/s eta 0:00:05\n",
      "   --------------------------- ------------ 1.0/1.5 MB 95.4 kB/s eta 0:00:05\n",
      "   --------------------------- ------------ 1.0/1.5 MB 95.4 kB/s eta 0:00:05\n",
      "   ---------------------------------- ----- 1.3/1.5 MB 96.9 kB/s eta 0:00:03\n",
      "   ---------------------------------- ----- 1.3/1.5 MB 96.9 kB/s eta 0:00:03\n",
      "   ---------------------------------- ----- 1.3/1.5 MB 96.9 kB/s eta 0:00:03\n",
      "   ---------------------------------- ----- 1.3/1.5 MB 96.9 kB/s eta 0:00:03\n",
      "   ---------------------------------- ----- 1.3/1.5 MB 96.9 kB/s eta 0:00:03\n",
      "   ---------------------------------- ----- 1.3/1.5 MB 96.9 kB/s eta 0:00:03\n",
      "   ---------------------------------- ----- 1.3/1.5 MB 96.9 kB/s eta 0:00:03\n",
      "   ---------------------------------- ----- 1.3/1.5 MB 96.9 kB/s eta 0:00:03\n",
      "   ---------------------------------- ----- 1.3/1.5 MB 96.9 kB/s eta 0:00:03\n",
      "   ---------------------------------- ----- 1.3/1.5 MB 96.9 kB/s eta 0:00:03\n",
      "   ---------------------------------------- 1.5/1.5 MB 96.4 kB/s  0:00:15\n",
      "Downloading regex-2025.9.18-cp313-cp313-win_amd64.whl (275 kB)\n",
      "Downloading click-8.3.0-py3-none-any.whl (107 kB)\n",
      "Downloading tqdm-4.67.1-py3-none-any.whl (78 kB)\n",
      "Installing collected packages: tqdm, regex, click, nltk, textblob\n",
      "\n",
      "   ---------------------------------------- 0/5 [tqdm]\n",
      "   ---------------------------------------- 0/5 [tqdm]\n",
      "   ---------------------------------------- 0/5 [tqdm]\n",
      "   ---------------------------------------- 0/5 [tqdm]\n",
      "   ---------------------------------------- 0/5 [tqdm]\n",
      "   -------- ------------------------------- 1/5 [regex]\n",
      "   -------- ------------------------------- 1/5 [regex]\n",
      "   ---------------- ----------------------- 2/5 [click]\n",
      "   ---------------- ----------------------- 2/5 [click]\n",
      "   ---------------- ----------------------- 2/5 [click]\n",
      "   ---------------- ----------------------- 2/5 [click]\n",
      "   ------------------------ --------------- 3/5 [nltk]\n",
      "   ------------------------ --------------- 3/5 [nltk]\n",
      "   ------------------------ --------------- 3/5 [nltk]\n",
      "   ------------------------ --------------- 3/5 [nltk]\n",
      "   ------------------------ --------------- 3/5 [nltk]\n",
      "   ------------------------ --------------- 3/5 [nltk]\n",
      "   ------------------------ --------------- 3/5 [nltk]\n",
      "   ------------------------ --------------- 3/5 [nltk]\n",
      "   ------------------------ --------------- 3/5 [nltk]\n",
      "   ------------------------ --------------- 3/5 [nltk]\n",
      "   ------------------------ --------------- 3/5 [nltk]\n",
      "   ------------------------ --------------- 3/5 [nltk]\n",
      "   ------------------------ --------------- 3/5 [nltk]\n",
      "   ------------------------ --------------- 3/5 [nltk]\n",
      "   ------------------------ --------------- 3/5 [nltk]\n",
      "   ------------------------ --------------- 3/5 [nltk]\n",
      "   ------------------------ --------------- 3/5 [nltk]\n",
      "   ------------------------ --------------- 3/5 [nltk]\n",
      "   ------------------------ --------------- 3/5 [nltk]\n",
      "   ------------------------ --------------- 3/5 [nltk]\n",
      "   ------------------------ --------------- 3/5 [nltk]\n",
      "   ------------------------ --------------- 3/5 [nltk]\n",
      "   ------------------------ --------------- 3/5 [nltk]\n",
      "   ------------------------ --------------- 3/5 [nltk]\n",
      "   ------------------------ --------------- 3/5 [nltk]\n",
      "   ------------------------ --------------- 3/5 [nltk]\n",
      "   ------------------------ --------------- 3/5 [nltk]\n",
      "   ------------------------ --------------- 3/5 [nltk]\n",
      "   ------------------------ --------------- 3/5 [nltk]\n",
      "   ------------------------ --------------- 3/5 [nltk]\n",
      "   ------------------------ --------------- 3/5 [nltk]\n",
      "   ------------------------ --------------- 3/5 [nltk]\n",
      "   ------------------------ --------------- 3/5 [nltk]\n",
      "   ------------------------ --------------- 3/5 [nltk]\n",
      "   ------------------------ --------------- 3/5 [nltk]\n",
      "   ------------------------ --------------- 3/5 [nltk]\n",
      "   ------------------------ --------------- 3/5 [nltk]\n",
      "   ------------------------ --------------- 3/5 [nltk]\n",
      "   ------------------------ --------------- 3/5 [nltk]\n",
      "   ------------------------ --------------- 3/5 [nltk]\n",
      "   ------------------------ --------------- 3/5 [nltk]\n",
      "   ------------------------ --------------- 3/5 [nltk]\n",
      "   ------------------------ --------------- 3/5 [nltk]\n",
      "   ------------------------ --------------- 3/5 [nltk]\n",
      "   ------------------------ --------------- 3/5 [nltk]\n",
      "   ------------------------ --------------- 3/5 [nltk]\n",
      "   ------------------------ --------------- 3/5 [nltk]\n",
      "   ------------------------ --------------- 3/5 [nltk]\n",
      "   ------------------------ --------------- 3/5 [nltk]\n",
      "   ------------------------ --------------- 3/5 [nltk]\n",
      "   ------------------------ --------------- 3/5 [nltk]\n",
      "   ------------------------ --------------- 3/5 [nltk]\n",
      "   ------------------------ --------------- 3/5 [nltk]\n",
      "   ------------------------ --------------- 3/5 [nltk]\n",
      "   ------------------------ --------------- 3/5 [nltk]\n",
      "   ------------------------ --------------- 3/5 [nltk]\n",
      "   ------------------------ --------------- 3/5 [nltk]\n",
      "   ------------------------ --------------- 3/5 [nltk]\n",
      "   ------------------------ --------------- 3/5 [nltk]\n",
      "   ------------------------ --------------- 3/5 [nltk]\n",
      "   ------------------------ --------------- 3/5 [nltk]\n",
      "   ------------------------ --------------- 3/5 [nltk]\n",
      "   ------------------------ --------------- 3/5 [nltk]\n",
      "   ------------------------ --------------- 3/5 [nltk]\n",
      "   ------------------------ --------------- 3/5 [nltk]\n",
      "   ------------------------ --------------- 3/5 [nltk]\n",
      "   ------------------------ --------------- 3/5 [nltk]\n",
      "   ------------------------ --------------- 3/5 [nltk]\n",
      "   ------------------------ --------------- 3/5 [nltk]\n",
      "   ------------------------ --------------- 3/5 [nltk]\n",
      "   ------------------------ --------------- 3/5 [nltk]\n",
      "   ------------------------ --------------- 3/5 [nltk]\n",
      "   ------------------------ --------------- 3/5 [nltk]\n",
      "   ------------------------ --------------- 3/5 [nltk]\n",
      "   -------------------------------- ------- 4/5 [textblob]\n",
      "   -------------------------------- ------- 4/5 [textblob]\n",
      "   -------------------------------- ------- 4/5 [textblob]\n",
      "   -------------------------------- ------- 4/5 [textblob]\n",
      "   -------------------------------- ------- 4/5 [textblob]\n",
      "   ---------------------------------------- 5/5 [textblob]\n",
      "\n",
      "Successfully installed click-8.3.0 nltk-3.9.1 regex-2025.9.18 textblob-0.19.0 tqdm-4.67.1\n"
     ]
    }
   ],
   "source": [
    "# step 1: regsiter in X and create your app to get your keys\n",
    "# step 2: install dependencies\n",
    "!pip install tweepy # for accessing the Twitter (X) API\n",
    "!pip install textblob # for the sentiment analysis\n",
    "# note: you may want to do this in terminal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f9164a83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^C\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package brown to\n",
      "[nltk_data]     C:\\Users\\ael\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping corpora\\brown.zip.\n",
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     C:\\Users\\ael\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers\\punkt_tab.zip.\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\ael\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger_eng to\n",
      "[nltk_data]     C:\\Users\\ael\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping taggers\\averaged_perceptron_tagger_eng.zip.\n",
      "[nltk_data] Downloading package conll2000 to\n",
      "[nltk_data]     C:\\Users\\ael\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping corpora\\conll2000.zip.\n",
      "[nltk_data] Downloading package movie_reviews to\n",
      "[nltk_data]     C:\\Users\\ael\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping corpora\\movie_reviews.zip.\n"
     ]
    }
   ],
   "source": [
    "# optional step, to fix an error\n",
    "!python -m textblob.download_corpora\n",
    "# again i'll download in terminal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad148ba4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('My', 'PRP$'),\n",
       " ('freaking', 'NN'),\n",
       " ('cardio', 'NN'),\n",
       " ('told', 'VBD'),\n",
       " ('me', 'PRP'),\n",
       " ('to', 'TO'),\n",
       " ('freaking', 'VBG'),\n",
       " ('exercise', 'NN'),\n",
       " ('They', 'PRP'),\n",
       " ('said', 'VBD'),\n",
       " ('that', 'IN'),\n",
       " ('I', 'PRP'),\n",
       " ('was', 'VBD'),\n",
       " ('still', 'RB'),\n",
       " ('young', 'JJ'),\n",
       " ('and', 'CC'),\n",
       " ('should', 'MD'),\n",
       " ('be', 'VB'),\n",
       " ('active', 'JJ')]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# step 3 import TextBlob\n",
    "from textblob import TextBlob \n",
    "\n",
    "# step 4: the actual code\n",
    "wiki = TextBlob(\"My freaking cardio told me to freaking exercise. They said that I was still young and should be active\")\n",
    "wiki.tags # this shows you the parts of speech\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5625956f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "WordList(['My', 'freaking', 'cardio', 'told', 'me', 'to', 'freaking', 'exercise', 'They', 'said', 'that', 'I', 'was', 'still', 'young', 'and', 'should', 'be', 'active'])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wiki.words # this shows you the attributes of the text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00083618",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Negative sentiment\n"
     ]
    }
   ],
   "source": [
    "wiki.sentiment.polarity # this shows you the sentiment polarity, -1 to 1, negative to positive\n",
    "if wiki.sentiment.polarity > 0:\n",
    "    print(\"Positive sentiment\")\n",
    "elif wiki.sentiment.polarity < 0:\n",
    "    print(\"Negative sentiment\")\n",
    "else:\n",
    "    print(\"Neutral sentiment\") # this automatically classifies the sentiment\n",
    "    # you can fine tune it by adding more criteria based on more defined ranges in the spectrum"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09810d5c",
   "metadata": {},
   "source": [
    "### now that we know how the sentiment analysis works, its time to apply it to twitter posts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b78d7e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# step 1 utilizing the Twitter API to get tweets\n",
    "consumer_key = 'CBGCbthmo5OakvJIiOkHz7BQ4'\n",
    "consumer_secret = 'GZMROxEekoKLJ6Qc2UkjSfQEBRbY4k3qKAd5LZ7yPRuANFc8lK'\n",
    "access_token = '1969079309588709377-VuFqIMeyl0tOoBDIR5bym4lyF47uAt'\n",
    "access_token_secret = 'p3zugxdtT7xzL12FyWELefKwFDNS8JKGPWm7gtLBzFbK3'\n",
    "# I will regenerate these keys after this demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff34873f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# step 2: authenticate to the API and create the API object\n",
    "\n",
    "import tweepy as tpy # forgot to import this earlier, lol\n",
    "auth = tpy.OAuthHandler(consumer_key, consumer_secret) # sets auth method\n",
    "auth.set_access_token(access_token, access_token_secret) # sets access method \n",
    "api = tpy.API(auth) # create the API object\n",
    "\n",
    "### api object used to access the API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0afbfa7e",
   "metadata": {},
   "outputs": [
    {
     "ename": "Forbidden",
     "evalue": "403 Forbidden\n453 - You currently have access to a subset of X API V2 endpoints and limited v1.1 endpoints (e.g. media post, oauth) only. If you need access to this endpoint, you may need a different access level. You can learn more here: https://developer.x.com/en/portal/product",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mForbidden\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[25]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# step 3 utilizing the API object to get tweets\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m public_tweets = \u001b[43mapi\u001b[49m\u001b[43m.\u001b[49m\u001b[43msearch_tweets\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mElon\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;66;03m# search for tweets with the keyword 'Elon'\u001b[39;00m\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m tweet \u001b[38;5;129;01min\u001b[39;00m public_tweets:\n\u001b[32m      5\u001b[39m     \u001b[38;5;28mprint\u001b[39m(tweet.text) \u001b[38;5;66;03m# print the text of each tweet\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\ael\\OneDrive\\Desktop\\138\\.venv\\Lib\\site-packages\\tweepy\\api.py:32\u001b[39m, in \u001b[36mpagination.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m     30\u001b[39m \u001b[38;5;129m@functools\u001b[39m.wraps(method)\n\u001b[32m     31\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mwrapper\u001b[39m(*args, **kwargs):\n\u001b[32m---> \u001b[39m\u001b[32m32\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmethod\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\ael\\OneDrive\\Desktop\\138\\.venv\\Lib\\site-packages\\tweepy\\api.py:45\u001b[39m, in \u001b[36mpayload.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m     43\u001b[39m kwargs[\u001b[33m'\u001b[39m\u001b[33mpayload_list\u001b[39m\u001b[33m'\u001b[39m] = payload_list\n\u001b[32m     44\u001b[39m kwargs[\u001b[33m'\u001b[39m\u001b[33mpayload_type\u001b[39m\u001b[33m'\u001b[39m] = payload_type\n\u001b[32m---> \u001b[39m\u001b[32m45\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmethod\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\ael\\OneDrive\\Desktop\\138\\.venv\\Lib\\site-packages\\tweepy\\api.py:1221\u001b[39m, in \u001b[36mAPI.search_tweets\u001b[39m\u001b[34m(self, q, **kwargs)\u001b[39m\n\u001b[32m   1117\u001b[39m \u001b[38;5;129m@pagination\u001b[39m(mode=\u001b[33m'\u001b[39m\u001b[33mid\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m   1118\u001b[39m \u001b[38;5;129m@payload\u001b[39m(\u001b[33m'\u001b[39m\u001b[33msearch_results\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m   1119\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34msearch_tweets\u001b[39m(\u001b[38;5;28mself\u001b[39m, q, **kwargs):\n\u001b[32m   1120\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"search_tweets(q, *, geocode, lang, locale, result_type, count, \\\u001b[39;00m\n\u001b[32m   1121\u001b[39m \u001b[33;03m                     until, since_id, max_id, include_entities)\u001b[39;00m\n\u001b[32m   1122\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m   1219\u001b[39m \u001b[33;03m        2023.: https://twittercommunity.com/t/x-api-v2-migration/203391\u001b[39;00m\n\u001b[32m   1220\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1221\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1222\u001b[39m \u001b[43m        \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mGET\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43msearch/tweets\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mendpoint_parameters\u001b[49m\u001b[43m=\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1223\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mq\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mgeocode\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mlang\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mlocale\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mresult_type\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mcount\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   1224\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43muntil\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43msince_id\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mmax_id\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43minclude_entities\u001b[39;49m\u001b[33;43m'\u001b[39;49m\n\u001b[32m   1225\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mq\u001b[49m\u001b[43m=\u001b[49m\u001b[43mq\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\n\u001b[32m   1226\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\ael\\OneDrive\\Desktop\\138\\.venv\\Lib\\site-packages\\tweepy\\api.py:270\u001b[39m, in \u001b[36mAPI.request\u001b[39m\u001b[34m(self, method, endpoint, endpoint_parameters, params, headers, json_payload, parser, payload_list, payload_type, post_data, files, require_auth, return_cursors, upload_api, use_cache, **kwargs)\u001b[39m\n\u001b[32m    268\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m Unauthorized(resp)\n\u001b[32m    269\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m resp.status_code == \u001b[32m403\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m270\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m Forbidden(resp)\n\u001b[32m    271\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m resp.status_code == \u001b[32m404\u001b[39m:\n\u001b[32m    272\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m NotFound(resp)\n",
      "\u001b[31mForbidden\u001b[39m: 403 Forbidden\n453 - You currently have access to a subset of X API V2 endpoints and limited v1.1 endpoints (e.g. media post, oauth) only. If you need access to this endpoint, you may need a different access level. You can learn more here: https://developer.x.com/en/portal/product"
     ]
    }
   ],
   "source": [
    "# step 3 utilizing the API object to get tweets\n",
    "public_tweets = api.search_tweets('Elon') # search for tweets with the keyword 'Elon'\n",
    "\n",
    "for tweet in public_tweets:\n",
    "    print(tweet.text) # print the text of each tweet\n",
    "    analysis = TextBlob(tweet.text) # perform sentiment analysis on the tweet text\n",
    "    print(analysis.sentiment) # print the sentiment analysis result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "565c47b1",
   "metadata": {},
   "source": [
    "### apparantly, i don't have access LOL, but it's okay. \n",
    "**my learnings so far** \n",
    "- you can use sentiment analysis to analyze human behavior based on a text \n",
    "- api's are cool! you can use them to do some operations on the server using your code\n",
    "- however, to utilize api's you need authentications and keys"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
